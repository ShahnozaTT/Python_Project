{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cb8f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 100 rows\n",
      "[{'id': 'ae76eeed-0a1d-499a-9468-a83860bacf29', 'comm_type': 'meeting', 'raw_content': '{\"id\": \"814BCF8700744AAFABD21C3B\", \"title\": \"Multi-tiered attitude-oriented neural-net\", \"duration\": 141.23, \"calendar_id\": \"67F4E7983B84476A9D9A8EA8941EDC1C\", \"audio_url\": \"https://lee.com//audio.mp3\", \"video_url\": \"http://www.james.com//video.mp4\", \"transcript_url\": \"http://clark-adams.com//transcript.txt\", \"dateString\": \"2025-08-25 13:30:44\", \"host_email\": \"figueroajohn@doyle.net\", \"organizer_email\": \"fjohnson@hall.com\", \"participants\": [\"lrobinson@pacheco-smith.com\", \"joshua35@gmail.com\"], \"speakers\": [\"wdavis@baker.com\"], \"meeting_attendees\": [{\"email\": \"lrobinson@pacheco-smith.com\"}, {\"email\": \"joshua35@gmail.com\"}]}', 'subject': 'Sharable composite monitoring', 'source_id': '814BCF8700744AAFABD21C3B', 'ingested_at': '2025-04-06T01:48:11+00:00', 'processed_at': '2025-03-05T11:01:17+00:00', 'is_processed': True}, {'id': '924be5c7-9a1d-4c0f-897b-9abc9d61a9ef', 'comm_type': 'email', 'raw_content': '{\"id\": \"75CA815AEE4143BCAF25DD35\", \"title\": \"Cloned human-resource implementation\", \"duration\": 140.47, \"calendar_id\": \"DF99A391725F454EA282FCF4B92196E7\", \"audio_url\": \"https://valencia.net//audio.mp3\", \"video_url\": \"https://carter.info//video.mp4\", \"transcript_url\": \"http://gill.com//transcript.txt\", \"dateString\": \"2025-09-06 03:26:27\", \"host_email\": \"onelson@hotmail.com\", \"organizer_email\": \"megan03@trujillo.com\", \"participants\": [\"robinbradley@edwards.info\", \"donald88@burgess-patterson.org\", \"jeffrey28@yahoo.com\"], \"speakers\": [\"callahaneric@conner.org\"], \"meeting_attendees\": [{\"email\": \"robinbradley@edwards.info\"}, {\"email\": \"donald88@burgess-patterson.org\"}, {\"email\": \"jeffrey28@yahoo.com\"}]}', 'subject': 'Profit-focused real-time customer loyalty', 'source_id': '75CA815AEE4143BCAF25DD35', 'ingested_at': '2025-03-01T08:33:54+00:00', 'processed_at': '2025-05-26T05:07:46+00:00', 'is_processed': True}, {'id': '8fe7b155-8aac-43b7-a813-d6acc69a50ea', 'comm_type': 'meeting', 'raw_content': '{\"id\": \"7BFB762A59674089A2D9D487\", \"title\": \"Centralized impactful superstructure\", \"duration\": 34.47, \"calendar_id\": \"1DFB61F4812E4DBCA5186A518FC16A5E\", \"audio_url\": \"https://www.lee.info//audio.mp3\", \"video_url\": \"http://ramirez.com//video.mp4\", \"transcript_url\": \"https://www.pearson.com//transcript.txt\", \"dateString\": \"2025-02-06 05:16:19\", \"host_email\": \"georgetracy@hickman.com\", \"organizer_email\": \"nataliearroyo@dennis.net\", \"participants\": [\"donnaarroyo@baker.biz\", \"jenniferross@santos.com\", \"calebsmith@hall.com\", \"whiteheadmichele@palmer.info\", \"jenniferkhan@kennedy.com\"], \"speakers\": [\"hopkinsmichael@owens-daniel.com\"], \"meeting_attendees\": [{\"email\": \"donnaarroyo@baker.biz\"}, {\"email\": \"jenniferross@santos.com\"}, {\"email\": \"calebsmith@hall.com\"}, {\"email\": \"whiteheadmichele@palmer.info\"}, {\"email\": \"jenniferkhan@kennedy.com\"}]}', 'subject': 'Versatile disintermediate concept', 'source_id': '7BFB762A59674089A2D9D487', 'ingested_at': '2025-06-07T20:03:12+00:00', 'processed_at': '2025-07-08T14:30:12+00:00', 'is_processed': True}, {'id': '8a6d97c0-2925-4314-9f2f-4aee7e71a580', 'comm_type': 'meeting', 'raw_content': '{\"id\": \"F46243983B87433BABE96151\", \"title\": \"Persevering regional open system\", \"duration\": 120.3, \"calendar_id\": \"23AB4C72C0AF40CDB68293F35D7253FB\", \"audio_url\": \"http://www.lewis.com//audio.mp3\", \"video_url\": \"http://moore-bass.com//video.mp4\", \"transcript_url\": \"http://garcia.com//transcript.txt\", \"dateString\": \"2025-08-03 20:25:05\", \"host_email\": \"michellebarrera@gmail.com\", \"organizer_email\": \"gallowayjoseph@yahoo.com\", \"participants\": [\"uhorton@hotmail.com\", \"jamesrobinson@gmail.com\", \"brian97@calhoun.net\"], \"speakers\": [\"caseyjones@powell.com\", \"barnesbrandy@stewart.com\", \"randy47@hickman-walls.com\"], \"meeting_attendees\": [{\"email\": \"uhorton@hotmail.com\"}, {\"email\": \"jamesrobinson@gmail.com\"}, {\"email\": \"brian97@calhoun.net\"}]}', 'subject': 'Distributed encompassing forecast', 'source_id': 'F46243983B87433BABE96151', 'ingested_at': '2025-08-23T21:25:21+00:00', 'processed_at': '2025-03-23T19:12:38+00:00', 'is_processed': True}, {'id': 'a16d7eca-8316-44cf-80d7-48dcc4df5d5c', 'comm_type': 'chat', 'raw_content': '{\"id\": \"6709DA4EF5F34AA093A6E9EF\", \"title\": \"Enhanced incremental algorithm\", \"duration\": 97.38, \"calendar_id\": \"FFCD2BD827E44A17AA6B83520E6BEA20\", \"audio_url\": \"http://pham-shields.com//audio.mp3\", \"video_url\": \"https://www.rodriguez.com//video.mp4\", \"transcript_url\": \"http://torres-pope.com//transcript.txt\", \"dateString\": \"2025-03-28 13:47:53\", \"host_email\": \"gracefarrell@hotmail.com\", \"organizer_email\": \"rebecca01@hotmail.com\", \"participants\": [\"bradley52@hotmail.com\", \"joycearnold@yahoo.com\", \"jonesnicole@gardner.org\", \"tanderson@nolan-flynn.com\", \"evelynestrada@yahoo.com\"], \"speakers\": [\"sarayoung@gmail.com\"], \"meeting_attendees\": [{\"email\": \"bradley52@hotmail.com\"}, {\"email\": \"joycearnold@yahoo.com\"}, {\"email\": \"jonesnicole@gardner.org\"}, {\"email\": \"tanderson@nolan-flynn.com\"}, {\"email\": \"evelynestrada@yahoo.com\"}]}', 'subject': 'Assimilated stable core', 'source_id': '6709DA4EF5F34AA093A6E9EF', 'ingested_at': '2025-06-04T17:58:19+00:00', 'processed_at': '2025-05-08T11:37:23+00:00', 'is_processed': True}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Supabase endpoint\n",
    "url = \"https://xrfvuwgjrlznxdhiqded.supabase.co/rest/v1/commdata\"\n",
    "\n",
    "# Authentication headers\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhyZnZ1d2dqcmx6bnhkaGlxZGVkIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NzQ5NzEyNSwiZXhwIjoyMDczMDczMTI1fQ.sFT6MsN7Phla94BIyHXRjiLZB8TLQof9U17Rv51XJaM\",\n",
    "    \"apikey\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhyZnZ1d2dqcmx6bnhkaGlxZGVkIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1NzQ5NzEyNSwiZXhwIjoyMDczMDczMTI1fQ.sFT6MsN7Phla94BIyHXRjiLZB8TLQof9U17Rv51XJaM\"\n",
    "}\n",
    "\n",
    "# Query parameters: limit 100 rows\n",
    "params = {\n",
    "    \"limit\": 100\n",
    "}\n",
    "\n",
    "# Send GET request\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "# Check response\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(\"Retrieved\", len(data), \"rows\")\n",
    "    print(data[:5])  # print first 5 rows as sample\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a769ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 100 rows\n"
     ]
    }
   ],
   "source": [
    "params = {\"limit\": 1000}  # керакли қатор сони, мисол учун 1000\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    df_api = pd.DataFrame(data)  # df_api шу ерда яратилади\n",
    "    print(\"Retrieved\", len(df_api), \"rows\")\n",
    "else:\n",
    "    raise Exception(f\"Error fetching data: {response.status_code} {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a79e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '814BCF8700744AAFABD21C3B', 'title': 'Multi-tiered attitude-oriented neural-net', 'duration': 141.23, 'calendar_id': '67F4E7983B84476A9D9A8EA8941EDC1C', 'audio_url': 'https://lee.com//audio.mp3', 'video_url': 'http://www.james.com//video.mp4', 'transcript_url': 'http://clark-adams.com//transcript.txt', 'dateString': '2025-08-25 13:30:44', 'host_email': 'figueroajohn@doyle.net', 'organizer_email': 'fjohnson@hall.com', 'participants': ['lrobinson@pacheco-smith.com', 'joshua35@gmail.com'], 'speakers': ['wdavis@baker.com'], 'meeting_attendees': [{'email': 'lrobinson@pacheco-smith.com'}, {'email': 'joshua35@gmail.com'}]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# JSON → DataFrame\n",
    "df_api = pd.DataFrame(data)\n",
    "\n",
    "# parsed колонкасида JSON тарзидаги raw_content ни очиш\n",
    "df_api['parsed'] = df_api['raw_content'].apply(json.loads)\n",
    "\n",
    "# мисол учун биринчи қаторни текшириш\n",
    "print(df_api['parsed'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820f4aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables exported successfully to communications_numeric.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# -------------------------\n",
    "# 1️⃣ JSON ни очиш\n",
    "# -------------------------\n",
    "df_api_parsed = df_api.copy()\n",
    "df_api_parsed[\"title\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"title\"))\n",
    "df_api_parsed[\"duration\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"duration\"))\n",
    "df_api_parsed[\"calendar_id\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"calendar_id\"))\n",
    "df_api_parsed[\"audio_url\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"audio_url\"))\n",
    "df_api_parsed[\"video_url\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"video_url\"))\n",
    "df_api_parsed[\"transcript_url\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"transcript_url\"))\n",
    "df_api_parsed[\"dateString\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"dateString\"))\n",
    "df_api_parsed[\"host_email\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"host_email\"))\n",
    "df_api_parsed[\"organizer_email\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"organizer_email\"))\n",
    "df_api_parsed[\"speakers\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"speakers\", []))\n",
    "df_api_parsed[\"participants\"] = df_api_parsed[\"parsed\"].apply(lambda x: x.get(\"participants\", []))\n",
    "df_api_parsed[\"meeting_attendees\"] = df_api_parsed[\"parsed\"].apply(lambda x: [d[\"email\"] for d in x.get(\"meeting_attendees\", [])])\n",
    "\n",
    "# -------------------------\n",
    "# 2️⃣ Dimension таблицалар\n",
    "# -------------------------\n",
    "# comm_type\n",
    "dim_comm_type = pd.DataFrame({\"comm_type\": [\"meeting\", \"call\", \"chat\"]})\n",
    "dim_comm_type['comm_type_id'] = range(1, len(dim_comm_type)+1)\n",
    "\n",
    "# subject\n",
    "dim_subject = pd.DataFrame({\"subject_name\": df_api_parsed[\"title\"].unique()})\n",
    "dim_subject['subject_id'] = range(1, len(dim_subject)+1)\n",
    "\n",
    "# user\n",
    "all_emails = set(df_api_parsed[\"speakers\"].sum() + df_api_parsed[\"participants\"].sum() + df_api_parsed[\"meeting_attendees\"].sum() + df_api_parsed[\"organizer_email\"].dropna().tolist() + df_api_parsed[\"host_email\"].dropna().tolist())\n",
    "dim_user = pd.DataFrame({\"user_email\": list(all_emails)})\n",
    "dim_user['user_id'] = range(1, len(dim_user)+1)\n",
    "\n",
    "# calendar\n",
    "dim_calendar = pd.DataFrame({\"calendar_id\": df_api_parsed[\"calendar_id\"].unique()})\n",
    "dim_calendar['calendar_numeric_id'] = range(1, len(dim_calendar)+1)\n",
    "\n",
    "# audio/video/transcript\n",
    "dim_audio = pd.DataFrame({\"audio_url\": df_api_parsed[\"audio_url\"].unique()})\n",
    "dim_audio['audio_id'] = range(1, len(dim_audio)+1)\n",
    "\n",
    "dim_video = pd.DataFrame({\"video_url\": df_api_parsed[\"video_url\"].unique()})\n",
    "dim_video['video_id'] = range(1, len(dim_video)+1)\n",
    "\n",
    "dim_transcript = pd.DataFrame({\"transcript_url\": df_api_parsed[\"transcript_url\"].unique()})\n",
    "dim_transcript['transcript_id'] = range(1, len(dim_transcript)+1)\n",
    "\n",
    "# -------------------------\n",
    "# 3️⃣ bridge_comm_user\n",
    "# -------------------------\n",
    "email_to_id = dict(zip(dim_user['user_email'], dim_user['user_id']))\n",
    "bridge_rows = []\n",
    "\n",
    "for idx, row in df_api_parsed.iterrows():\n",
    "    comm_id = row['id']\n",
    "\n",
    "    # Speakers\n",
    "    for email in row['speakers']:\n",
    "        uid = email_to_id.get(email)\n",
    "        if uid is None:\n",
    "            continue\n",
    "        bridge_rows.append({\n",
    "            \"comm_id\": comm_id,\n",
    "            \"user_id\": uid,\n",
    "            \"isSpeaker\": True,\n",
    "            \"isParticipant\": False,\n",
    "            \"isAttendee\": False,\n",
    "            \"isOrganiser\": False\n",
    "        })\n",
    "\n",
    "    # Participants\n",
    "    for email in row['participants']:\n",
    "        uid = email_to_id.get(email)\n",
    "        if uid is None:\n",
    "            continue\n",
    "        existing = [r for r in bridge_rows if r['comm_id']==comm_id and r['user_id']==uid]\n",
    "        if existing:\n",
    "            existing[0]['isParticipant'] = True\n",
    "        else:\n",
    "            bridge_rows.append({\n",
    "                \"comm_id\": comm_id,\n",
    "                \"user_id\": uid,\n",
    "                \"isSpeaker\": False,\n",
    "                \"isParticipant\": True,\n",
    "                \"isAttendee\": False,\n",
    "                \"isOrganiser\": False\n",
    "            })\n",
    "\n",
    "    # Attendees\n",
    "    for email in row['meeting_attendees']:\n",
    "        uid = email_to_id.get(email)\n",
    "        if uid is None:\n",
    "            continue\n",
    "        existing = [r for r in bridge_rows if r['comm_id']==comm_id and r['user_id']==uid]\n",
    "        if existing:\n",
    "            existing[0]['isAttendee'] = True\n",
    "        else:\n",
    "            bridge_rows.append({\n",
    "                \"comm_id\": comm_id,\n",
    "                \"user_id\": uid,\n",
    "                \"isSpeaker\": False,\n",
    "                \"isParticipant\": False,\n",
    "                \"isAttendee\": True,\n",
    "                \"isOrganiser\": False\n",
    "            })\n",
    "\n",
    "    # Organiser / Host\n",
    "    for email in [row.get('organizer_email'), row.get('host_email')]:\n",
    "        if pd.notna(email):\n",
    "            uid = email_to_id.get(email)\n",
    "            if uid is None:\n",
    "                continue\n",
    "            existing = [r for r in bridge_rows if r['comm_id']==comm_id and r['user_id']==uid]\n",
    "            if existing:\n",
    "                existing[0]['isOrganiser'] = True\n",
    "            else:\n",
    "                bridge_rows.append({\n",
    "                    \"comm_id\": comm_id,\n",
    "                    \"user_id\": uid,\n",
    "                    \"isSpeaker\": False,\n",
    "                    \"isParticipant\": False,\n",
    "                    \"isAttendee\": False,\n",
    "                    \"isOrganiser\": True\n",
    "                })\n",
    "\n",
    "bridge_comm_user = pd.DataFrame(bridge_rows)\n",
    "\n",
    "# -------------------------\n",
    "# 4️⃣ Helper for numeric mapping\n",
    "# -------------------------\n",
    "def get_numeric_id(df_dim, value_column, value, id_column):\n",
    "    match = df_dim[df_dim[value_column]==value]\n",
    "    if not match.empty:\n",
    "        return match[id_column].values[0]\n",
    "    return None\n",
    "\n",
    "# -------------------------\n",
    "# 5️⃣ fact_communication\n",
    "# -------------------------\n",
    "fact_rows = []\n",
    "\n",
    "for idx, row in df_api_parsed.iterrows():\n",
    "    fact_rows.append({\n",
    "        \"comm_id\": row['id'],\n",
    "        \"raw_id\": row['id'],\n",
    "        \"source_id\": row['id'],\n",
    "        \"comm_type_id\": get_numeric_id(dim_comm_type, 'comm_type', \"meeting\", 'comm_type_id'),\n",
    "        \"subject_id\": get_numeric_id(dim_subject, 'subject_name', row['title'], 'subject_id'),\n",
    "        \"calendar_id\": get_numeric_id(dim_calendar, 'calendar_id', row['calendar_id'], 'calendar_numeric_id'),\n",
    "        \"audio_id\": get_numeric_id(dim_audio, 'audio_url', row['audio_url'], 'audio_id'),\n",
    "        \"video_id\": get_numeric_id(dim_video, 'video_url', row['video_url'], 'video_id'),\n",
    "        \"transcript_id\": get_numeric_id(dim_transcript, 'transcript_url', row['transcript_url'], 'transcript_id'),\n",
    "        \"datetime_id\": row['dateString'],\n",
    "        \"ingested_at\": pd.Timestamp.now(),\n",
    "        \"processed_at\": pd.Timestamp.now(),\n",
    "        \"is_processed\": True,\n",
    "        \"raw_title\": row['title'],\n",
    "        \"raw_duration\": row['duration']\n",
    "    })\n",
    "\n",
    "fact_communication = pd.DataFrame(fact_rows)\n",
    "\n",
    "# -------------------------\n",
    "# 6️⃣ Export to Excel\n",
    "# -------------------------\n",
    "output_file = \"communications_numeric.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    dim_comm_type.to_excel(writer, sheet_name='dim_comm_type', index=False)\n",
    "    dim_subject.to_excel(writer, sheet_name='dim_subject', index=False)\n",
    "    dim_user.to_excel(writer, sheet_name='dim_user', index=False)\n",
    "    dim_calendar.to_excel(writer, sheet_name='dim_calendar', index=False)\n",
    "    dim_audio.to_excel(writer, sheet_name='dim_audio', index=False)\n",
    "    dim_video.to_excel(writer, sheet_name='dim_video', index=False)\n",
    "    dim_transcript.to_excel(writer, sheet_name='dim_transcript', index=False)\n",
    "    fact_communication.to_excel(writer, sheet_name='fact_communication', index=False)\n",
    "    bridge_comm_user.to_excel(writer, sheet_name='bridge_comm_user', index=False)\n",
    "\n",
    "print(f\"All tables exported successfully to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4d39ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Microsoft VS Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90f07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2a343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
